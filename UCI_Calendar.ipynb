{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "UCI_Calendar.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyM392IMPLtz+p0Ohqp3VSAe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lweislo/UCI_data/blob/main/UCI_Calendar.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6cqGuiI99q-"
      },
      "source": [
        "This script will get the full calendar from the UCI API.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pg8lz23p98BR"
      },
      "source": [
        "# Dependencies\n",
        "import pandas as pd\n",
        "import requests\n",
        "import json\n",
        "from bs4 import BeautifulSoup\n",
        "from google.colab import files\n",
        "# First get the URLs for each race since the API doesn't have category, class or country\n",
        "def get_calendar_links(url):\n",
        "    data = requests.get(url).json()\n",
        "    data = data['items']\n",
        "    event_list = []\n",
        "    try:\n",
        "        for item in data:\n",
        "            for i in item['items']:\n",
        "                for race in i['items']:\n",
        "                    event_list.append(\"https://www.uci.org\" + race['detailsLink']['url'])\n",
        "    except TypeError:\n",
        "        print(f'Missing data from an item, skipping')\n",
        "        pass\n",
        "    get_race_calendar_data(event_list)\n",
        "\n",
        "# Then iterate through all the URLs to get the information you need\n",
        "def get_race_calendar_data(url_list):\n",
        "    df = pd.DataFrame()\n",
        "    for item in url_list:\n",
        "        page = requests.get(item)\n",
        "        print(f'Getting data from {item}')\n",
        "        try:\n",
        "            if page.status_code == 200:\n",
        "                content = page.content\n",
        "                soup = BeautifulSoup(content, \"html5lib\")\n",
        "                info = soup.find('div',{'data-component':'CompetitionDetailsModule'})\n",
        "                race_info = json.loads(info['data-props'])\n",
        "                race_dict = {'Race': race_info['competitionDetails']['name'], 'Class':race_info['competitionDetails']['competitionClass'], 'Dates': race_info['competitionDetails']['dates'], 'Country':race_info['competitionDetails']['country'],'Category':race_info['schedule']['items'][0]['races'][0]['category']}\n",
        "                df = df.append(race_dict, ignore_index=True)\n",
        "        except TyperError:\n",
        "            print(f'Missing data from {item} - skipped')\n",
        "            pass\n",
        "        \n",
        "    df_deduped = df.drop_duplicates(subset=['Race','Category'])\n",
        "    outfile = 'uci_calendar.txt'\n",
        "    with open(outfile, 'w') as file:\n",
        "        file.write(df_deduped.to_csv(header=True, index=False, encoding='UTF-8', sep='\\t'))\n",
        "    files.download(outfile)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4zAmewE-UM9"
      },
      "source": [
        "# Enter the URL for the API - this is for road. Change last three letters to MTB, CRO, PIS, BMX, BFR for mountain bike, cross, track, BMX, freestyle\n",
        "url = 'https://www.uci.org/api/calendar/upcoming?discipline=ROA'\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OLX5cr0K-Yg2"
      },
      "source": [
        "# Run the scraper\n",
        "get_calendar_links(url)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}